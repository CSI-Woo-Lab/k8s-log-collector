#######################################
# yaml file for random_job.py
# control jobs, node_and_gpu, batch_size, python train file.
#######################################

# possible python jobs
jobs : [
  # "vae",            
  # "yolov8n",        
  # "yolov8s",          
  # "yolov8m",          
  # "yolov8l",         
  # "yolov8x",          
  # "mnist",            
  # "mnist_rnn",       
  # "dcgan",          
  # "imagenet",     
  # "vision_transformer", 
  # "siamese_net",        
  # "super_resolution",   
  # "word_language", 
  # "gat", 
  # "Pytorch_vae", 
  # "Pytorch_vqvae",
  "offline_RL"
]

# batch size for RTX 3070ti, 4060
batch_size_for_8 : {
    "dcgan":[16, 32, 64, 128, 256, 512],
    "imagenet":[8, 16, 32, 64, 128],
    "vae":[64, 128, 256, 512], 
    "vision_transformer":[2, 4, 8], 
    "yolov8n":[2, 4, 8, 16],
    "yolov8s":[2, 4, 8, 16],
    "yolov8m":[2, 4, 8, 16],
    "yolov8l":[2, 4, 8, 16],
    "yolov8x":[2, 4, 8, 16],
    "mnist":[32, 64, 128, 256],
    "mnist_rnn":[32, 64, 128, 256],
    "siamese_net":[32, 64, 128, 256],
    "super_resolution":[4, 8, 16, 32, 64],
    "word_language" :[20, 40, 60, 80],
    "gat":[4, 8, 12, 16],
    "Pytorch_vae":[8, 16, 32, 64, 128, 256],
    "Pytorch_vqvae":[8, 16, 32, 64, 128, 256],
    "offline_RL" : [16, 32, 64, 128, 256, 512],
}

# batch size for RTX 4070
batch_size_for_12 : {
    "dcgan":[16, 32, 64, 128, 256, 512],
    "imagenet":[8, 16, 32, 64, 128, 256],
    "vae":[64, 128, 256, 512, 1024], 
    "vision_transformer":[2, 4, 8, 12], 
    "yolov8n":[2, 4, 8, 16, 32],
    "yolov8s":[2, 4, 8, 16, 32],
    "yolov8m":[2, 4, 8, 16, 32],
    "yolov8l":[2, 4, 8, 16, 32],
    "yolov8x":[2, 4, 8, 16],
    "mnist":[32, 64, 128, 256, 512],
    "mnist_rnn":[32, 64, 128, 256, 512],
    "siamese_net":[32, 64, 128, 256, 512],
    "super_resolution":[4, 8, 16, 32, 64],
    "word_language" :[20, 40, 60, 80, 100],
    "gat":[4, 8, 12, 16, 20],
    "Pytorch_vae":[8, 16, 32, 64, 128, 256],
    "Pytorch_vqvae":[8, 16, 32, 64, 128, 256],
    "offline_RL" : [16, 32, 64, 128, 256, 512]
}

# batch size for RTX 4080
batch_size_for_16 : {
    "dcgan":[16, 32, 64, 128, 256, 512, 1024],
    "imagenet":[8, 16, 32, 64, 128, 256],
    "vae":[64, 128, 256, 512, 1024, 2048], 
    "vision_transformer":[2, 4, 8, 12, 16], 
    "yolov8n":[2, 4, 8, 16, 32],
    "yolov8s":[2, 4, 8, 16, 32],
    "yolov8m":[2, 4, 8, 16, 32],
    "yolov8l":[2, 4, 8, 16, 32],
    "yolov8x":[2, 4, 8, 16],
    "mnist":[32, 64, 128, 256, 512, 1024],
    "mnist_rnn":[32, 64, 128, 256, 512, 1024],
    "siamese_net":[32, 64, 128, 256],
    "super_resolution":[4, 8, 16, 32, 64],
    "word_language" :[20, 40, 60, 80, 100],
    "gat":[8, 12, 16, 20, 24],
    "Pytorch_vae":[8, 16, 32, 64, 128, 256, 512],
    "Pytorch_vqvae":[8, 16, 32, 64, 128, 256, 512],
    "offline_RL" : [16, 32, 64, 128, 256, 512, 1024]
}

# batch size for RTX 3090, 4090
batch_size_for_24 : {
    "dcgan":[16, 32, 64, 128, 256, 512, 1024],
    "imagenet":[8, 16, 32, 64, 128, 256, 512],
    "vae":[64, 128, 256, 512, 1024, 2048, 4096], 
    "vision_transformer":[2, 4, 8, 12, 16, 32],  
    "yolov8n":[2, 4, 8, 16, 32],
    "yolov8s":[2, 4, 8, 16, 32],
    "yolov8m":[2, 4, 8, 16, 32],
    "yolov8l":[2, 4, 8, 16, 32],
    "yolov8x":[2, 4, 8, 16, 32],
    "mnist":[32, 64, 128, 256, 512, 1024],
    "mnist_rnn":[32, 64, 128, 256, 512, 1024],
    "siamese_net":[32, 64, 128, 256, 512],
    "super_resolution":[4, 8, 16, 32, 64, 128],
    "word_language" :[20, 40, 60, 80, 100, 120],
    "gat":[8, 12, 16, 20, 24, 28],
    "Pytorch_vae":[8, 16, 32, 64, 128, 256, 512],
    "Pytorch_vqvae":[8, 16, 32, 64, 128, 256, 512],
    "offline_RL" : [16, 32, 64, 128, 256, 512, 1024]
}

# Pytyon train file mapping to jobs
train_file : {
  "dcgan": "models/dcgan/main.py",
  "imagenet":"models/imagenet/main.py",
  "vae" : "models/vae/main.py",
  "vision_transformer" : "models/vision_transformer/main.py",
  "yolov8n": "models/Yolov8/main.py yolov8n.pt",
  "yolov8s": "models/Yolov8/main.py yolov8s.pt",
  "yolov8m": "models/Yolov8/main.py yolov8m.pt",
  "yolov8l": "models/Yolov8/main.py yolov8l.pt",
  "yolov8x": "models/Yolov8/main.py yolov8x.pt",
  "mnist" : "models/mnist/main.py",
  "mnist_rnn" : "models/mnist_rnn/main.py",
  "siamese_net": "models/siamese_network/main.py",
  "super_resolution": "models/super_resolution/main.py",
  "word_language": "models/word_language_model/main.py",
  "gat": "models/gat/main.py",
  "Pytorch_vae":"models/PyTorch-VAE/run.py",
  "Pytorch_vqvae":"models/PyTorch-VAE/vqvae_run.py",
  "offline_RL": "offlineRL_train_file",
}

offlineRL_model: [
          # "combo",
          "cql",
          "edac",
          # "iql",
          # "mcq",
          # "mobile",
          # "mopo",
          # "rambo",
          # "td3bc"
          ]

mujoco_env: ["halfcheetah-medium-v2", 
            "hopper-medium-v2", 
            "walker2d-medium-v2", 
            "halfcheetah-medium-replay-v2",
            "hopper-medium-replay-v2",
            "walker2d-medium-replay-v2",
            "halfcheetah-medium-expert-v2",
            "hopper-medium-expert-v2",
            "walker2d-medium-expert-v2"]

offlineRL_train_file: {
              # "combo": "models/OfflineRL-Kit/run_example/run_combo.py",
              "cql": "models/OfflineRL-Kit/run_example/run_cql.py",
              "edac": "models/OfflineRL-Kit/run_example/run_edac.py",
              "iql": "models/OfflineRL-Kit/run_example/run_iql.py",
              "mcq": "models/OfflineRL-Kit/run_example/run_mcq.py",
              # "mobile": "models/OfflineRL-Kit/run_example/run_mobile.py",
              # "mopo": "models/OfflineRL-Kit/run_example/run_mopo.py",
              # "rambo": "models/OfflineRL-Kit/run_example/run_rambo.py",
              "td3bc": "models/OfflineRL-Kit/run_example/run_td3bc.py",
}