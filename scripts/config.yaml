#######################################
# yaml file for random_job.py
# control jobs, node_and_gpu, batch_size, python train file.
#######################################

# possible python jobs
jobs : [
  "vae",            
  "yolov8n",        
  "yolov8s",          
  "yolov8m",          
  "yolov8l",         
  "yolov8x",          
  "mnist",            
  "mnist_rnn",       
  "dcgan",          
  "imagenet",     
  "vision_transformer", 
  "siamese_net",        
  "super_resolution",   
  "word_language", 
  "gat", 
  "Pytorch_vae", 
  "Pytorch_vqvae",
]

# batch size for RTX 3070ti, 4060
batch_size_for_8 : {
    "dcgan":[16, 32, 64, 128, 256, 512],
    "imagenet":[64, 128, 256, 512, 1024],
    "vae":[64, 128, 256, 512], 
    "vision_transformer":[2, 4, 8], 
    "yolov8n":[2, 4, 8],
    "yolov8s":[2, 4, 8],
    "yolov8m":[2, 4, 8],
    "yolov8l":[2, 4, 8],
    "yolov8x":[2, 4],
    "mnist":[32, 64, 128, 256],
    "mnist_rnn":[32, 64, 128, 256],
    "siamese_net":[32, 64, 128, 256],
    "super_resolution":[32, 64, 128, 256],
    "word_language" :[20, 40, 60, 80],
    "gat":[4, 8, 12, 16],
    "Pytorch_vae":[8, 16, 32, 64, 128, 256],
    "Pytorch_vqvae":[8, 16, 32, 64, 128, 256],
}

# batch size for RTX 4070
batch_size_for_12 : {
    "dcgan":[16, 32, 64, 128, 256, 512],
    "imagenet":[64, 128, 256, 512, 1024, 2048],
    "vae":[64, 128, 256, 512, 1024], 
    "vision_transformer":[2, 4, 8, 12], 
    "yolov8n":[2, 4, 8, 16],
    "yolov8s":[2, 4, 8],
    "yolov8m":[2, 4, 8],
    "yolov8l":[2, 4, 8],
    "yolov8x":[2, 4],
    "mnist":[32, 64, 128, 256, 512],
    "mnist_rnn":[32, 64, 128, 256, 512],
    "siamese_net":[32, 64, 128, 256, 512],
    "super_resolution":[32, 64, 128, 256, 512],
    "word_language" :[20, 40, 60, 80, 100],
    "gat":[4, 8, 12, 16, 20],
    "Pytorch_vae":[8, 16, 32, 64, 128, 256],
    "Pytorch_vqvae":[8, 16, 32, 64, 128, 256],
}

# batch size for RTX 4080
batch_size_for_16 : {
    "dcgan":[16, 32, 64, 128, 256, 512, 1024],
    "imagenet":[64, 128, 256, 512, 1024, 2048, 4096],
    "vae":[64, 128, 256, 512, 1024, 2048], 
    "vision_transformer":[2, 4, 8, 12, 16], 
    "yolov8n":[2, 4, 8, 16],
    "yolov8s":[2, 4, 8, 16],
    "yolov8m":[2, 4, 8],
    "yolov8l":[2, 4, 8],
    "yolov8x":[2, 4, 8],
    "mnist":[32, 64, 128, 256, 512, 1024],
    "mnist_rnn":[32, 64, 128, 256, 512, 1024],
    "siamese_net":[32, 64, 128, 256],
    "super_resolution":[32, 64, 128, 256, 512],
    "word_language" :[20, 40, 60, 80, 100],
    "gat":[4, 8, 12, 16, 20, 24],
    "Pytorch_vae":[8, 16, 32, 64, 128, 256, 512],
    "Pytorch_vqvae":[8, 16, 32, 64, 128, 256, 512],
}

# batch size for RTX 3090, 4090
batch_size_for_24 : {
    "dcgan":[16, 32, 64, 128, 256, 512, 1024],
    "imagenet":[64, 128, 256, 512, 1024, 2048, 4096],
    "vae":[64, 128, 256, 512, 1024, 2048, 4096], 
    "vision_transformer":[2, 4, 8, 12, 16, 32],  
    "yolov8n":[2, 4, 8, 16],
    "yolov8m":[2, 4, 8, 16],
    "yolov8s":[2, 4, 8, 16],
    "yolov8l":[2, 4, 8],
    "yolov8x":[2, 4, 8],
    "mnist":[32, 64, 128, 256, 512, 1024],
    "mnist_rnn":[32, 64, 128, 256, 512, 1024],
    "siamese_net":[32, 64, 128, 256, 512],
    "super_resolution":[32, 64, 128, 256, 512],
    "word_language" :[20, 40, 60, 80, 100, 120],
    "gat":[4, 8, 12, 16, 20, 24, 28],
    "Pytorch_vae":[8, 16, 32, 64, 128, 256, 512],
    "Pytorch_vqvae":[8, 16, 32, 64, 128, 256, 512]
}

# Pytyon train file mapping to jobs
train_file : {
  "dcgan": "models/dcgan/main.py",
  "imagenet":"models/imagenet/main.py",
  "vae" : "models/vae/main.py",
  "vision_transformer" : "models/vision_transformer/main.py",
  "yolov8n": "models/Yolov8/main.py yolov8n.pt",
  "yolov8s": "models/Yolov8/main.py yolov8s.pt",
  "yolov8m": "models/Yolov8/main.py yolov8m.pt",
  "yolov8l": "models/Yolov8/main.py yolov8l.pt",
  "yolov8x": "models/Yolov8/main.py yolov8x.pt",
  "mnist" : "models/mnist/main.py",
  "mnist_rnn" : "models/mnist_rnn/main.py",
  "siamese_net": "models/siamese_network/main.py",
  "super_resolution": "models/super_resolution/main.py",
  "word_language": "models/word_language_model/main.py",
  "gat": "models/gat/main.py",
  "Pytorch_vae":"models/PyTorch-VAE/run.py",
  "Pytorch_vqvae":"models/PyTorch-VAE/vqvae_run.py",
}