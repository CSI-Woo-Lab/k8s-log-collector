#######################################
# yaml file for random_job.py
# control jobs, node_and_gpu, batch_size, python train file.
#######################################

# possible python jobs
jobs : [
  # "yolov8n",
  # "yolov8s",
  # "yolov8m",
  # "yolov8l",
  # "yolov8x",
  # "mnist",
  # "mnist_rnn",
  # "dcgan",
  # "imagenet",
  # "vision_transformer",
  # "siamese_net",
  # "super_resolution",
  # "word_language",
  # "gat",
  # "Pytorch_vae",
  # "Pytorch_vqvae",
  # "cql",
  # "edac",
  # "iql",
  # "mcq",
  # "td3bc"
  "dnn_beamformer"
  # "video_classification"
]

# batch size for RTX 3070ti, 4060
batch_size_for_8 : {
    "dcgan":[16, 32, 64, 128, 256, 512],
    "imagenet":[8, 16, 32, 64, 128],
    "vision_transformer":[2, 4, 8], 
    "yolov8n":[2, 4, 8, 16],
    "yolov8s":[2, 4, 8, 16],
    "yolov8m":[2, 4, 8, 16],
    "yolov8l":[2, 4, 8, 16],
    "yolov8x":[2, 4, 8, 16],
    "mnist":[32, 64, 128, 256],
    "mnist_rnn":[32, 64, 128, 256],
    "siamese_net":[32, 64, 128, 256],
    "super_resolution":[4, 8, 16, 32, 64],
    "word_language" :[20, 40, 60, 80],
    "gat":[4, 8, 12, 16],
    "Pytorch_vae":[8, 16, 32, 64, 128, 256],
    "Pytorch_vqvae":[8, 16, 32, 64, 128, 256],
    "cql":[16, 32, 64, 128, 256, 512],
    "edac":[16, 32, 64, 128, 256, 512],
    "iql":[16, 32, 64, 128, 256, 512],
    "mcq":[16, 32, 64, 128, 256, 512],
    "td3bc":[16, 32, 64, 128, 256, 512],
    "dnn_beamformer":[4, 8, 16, 32],
    "video_classification":[4, 8, 12, 16],
    "image_size":[64, 128],
    "workers":[8],
}

# batch size for RTX 4070
batch_size_for_12 : {
    "dcgan":[16, 32, 64, 128, 256, 512],
    "imagenet":[8, 16, 32, 64, 128, 256],
    "vision_transformer":[2, 4, 8, 12], 
    "yolov8n":[2, 4, 8, 16, 32],
    "yolov8s":[2, 4, 8, 16, 32],
    "yolov8m":[2, 4, 8, 16, 32],
    "yolov8l":[2, 4, 8, 16, 32],
    "yolov8x":[2, 4, 8, 16],
    "mnist":[32, 64, 128, 256, 512],
    "mnist_rnn":[32, 64, 128, 256, 512],
    "siamese_net":[32, 64, 128, 256, 512],
    "super_resolution":[4, 8, 16, 32, 64],
    "word_language" :[20, 40, 60, 80, 100],
    "gat":[4, 8, 12, 16, 20],
    "Pytorch_vae":[8, 16, 32, 64, 128, 256],
    "Pytorch_vqvae":[8, 16, 32, 64, 128, 256],
    "cql":[16, 32, 64, 128, 256, 512],
    "edac":[16, 32, 64, 128, 256, 512],
    "iql":[16, 32, 64, 128, 256, 512],
    "mcq":[16, 32, 64, 128, 256, 512],
    "td3bc":[16, 32, 64, 128, 256, 512],
    "dnn_beamformer":[4, 8, 16, 32],
    "video_classification":[4, 8, 12, 16],
    "image_size":[64, 128],
    "workers":[8],
}

# batch size for RTX 4080
batch_size_for_16 : {
    "dcgan":[16, 32, 64, 128, 256, 512, 1024],
    "imagenet":[8, 16, 32, 64, 128, 256],
    "vision_transformer":[2, 4, 8, 12, 16], 
    "yolov8n":[2, 4, 8, 16, 32],
    "yolov8s":[2, 4, 8, 16, 32],
    "yolov8m":[2, 4, 8, 16, 32],
    "yolov8l":[2, 4, 8, 16, 32],
    "yolov8x":[2, 4, 8, 16],
    "mnist":[32, 64, 128, 256, 512, 1024],
    "mnist_rnn":[32, 64, 128, 256, 512, 1024],
    "siamese_net":[32, 64, 128, 256],
    "super_resolution":[4, 8, 16, 32, 64],
    "word_language" :[20, 40, 60, 80, 100],
    "gat":[8, 12, 16, 20, 24],
    "Pytorch_vae":[8, 16, 32, 64, 128, 256, 512],
    "Pytorch_vqvae":[8, 16, 32, 64, 128, 256, 512],
    "cql":[16, 32, 64, 128, 256, 512, 1024],
    "edac":[16, 32, 64, 128, 256, 512, 1024],
    "iql":[16, 32, 64, 128, 256, 512, 1024],
    "mcq":[16, 32, 64, 128, 256, 512, 1024],
    "td3bc":[16, 32, 64, 128, 256, 512],
    "dnn_beamformer":[4, 8, 16, 32, 64],
    "video_classification":[4, 8, 12, 16, 24],
    "image_size":[64, 128, 256],
    "workers":[16],
}

# batch size for RTX 3090, 4090
batch_size_for_24 : {
    "dcgan":[16, 32, 64, 128, 256, 512, 1024],
    "imagenet":[8, 16, 32, 64, 128, 256, 512],
    "vision_transformer":[2, 4, 8, 12, 16, 32],  
    "yolov8n":[2, 4, 8, 16, 32],
    "yolov8s":[2, 4, 8, 16, 32],
    "yolov8m":[2, 4, 8, 16, 32],
    "yolov8l":[2, 4, 8, 16, 32],
    "yolov8x":[2, 4, 8, 16, 32],
    "mnist":[32, 64, 128, 256, 512, 1024],
    "mnist_rnn":[32, 64, 128, 256, 512, 1024],
    "siamese_net":[32, 64, 128, 256, 512],
    "super_resolution":[4, 8, 16, 32, 64, 128],
    "word_language" :[20, 40, 60, 80, 100, 120],
    "gat":[8, 12, 16, 20, 24, 28],
    "Pytorch_vae":[8, 16, 32, 64, 128, 256, 512],
    "Pytorch_vqvae":[8, 16, 32, 64, 128, 256, 512],
    "cql":[16, 32, 64, 128, 256, 512, 1024],
    "edac":[16, 32, 64, 128, 256, 512, 1024],
    "iql":[16, 32, 64, 128, 256, 512, 1024],
    "mcq":[16, 32, 64, 128, 256, 512, 1024],
    "td3bc":[16, 32, 64, 128, 256, 512, 1024],
    "dnn_beamformer":[4, 8, 16, 32, 64],
    "video_classification":[4, 8, 12, 16, 24, 32],
    "image_size":[64, 128, 256],
    "workers":[16],
}

# Pytyon train file mapping to jobs
train_file : {
  "dcgan": "models/dcgan/main.py",
  "imagenet":"models/imagenet/main.py",
  "vision_transformer" : "models/vision_transformer/main.py",
  "yolov8n": "models/Yolov8/main.py yolov8n.pt",
  "yolov8s": "models/Yolov8/main.py yolov8s.pt",
  "yolov8m": "models/Yolov8/main.py yolov8m.pt",
  "yolov8l": "models/Yolov8/main.py yolov8l.pt",
  "yolov8x": "models/Yolov8/main.py yolov8x.pt",
  "mnist" : "models/mnist/main.py",
  "mnist_rnn" : "models/mnist_rnn/main.py",
  "siamese_net": "models/siamese_network/main.py",
  "super_resolution": "models/super_resolution/main.py",
  "word_language": "models/word_language_model/main.py",
  "gat": "models/gat/main.py",
  "Pytorch_vae":"models/PyTorch-VAE/run.py",
  "Pytorch_vqvae":"models/PyTorch-VAE/vqvae_run.py",
  "cql": "models/OfflineRL-Kit/run_example/run_cql.py",
  "edac": "models/OfflineRL-Kit/run_example/run_edac.py",
  "iql": "models/OfflineRL-Kit/run_example/run_iql.py",
  "mcq": "models/OfflineRL-Kit/run_example/run_mcq.py",
  "td3bc": "models/OfflineRL-Kit/run_example/run_td3bc.py",
  "dnn_beamformer":"models/dnn_beamformer/train.py",
  "video_classification":"models/video_classification/train.py",
}

mujoco_env: ["halfcheetah-medium-v2", 
            "hopper-medium-v2", 
            "walker2d-medium-v2", 
            "halfcheetah-medium-replay-v2",
            "hopper-medium-replay-v2",
            "walker2d-medium-replay-v2",
            "halfcheetah-medium-expert-v2",
            "hopper-medium-expert-v2",
            "walker2d-medium-expert-v2"]

datasets: {
  "dcgan":["imagenet_preprocess", "coco_preprocess", "cifar10_preprocess"],
  "imagenet":["cifar10"],
  "vision_transformer" : ["cifar10"],
  "yolov8n": ["VOC","VisDrone", "coco"],
  "yolov8s": ["VOC","VisDrone", "coco"],
  "yolov8m": ["VOC","VisDrone", "coco"],
  "yolov8l": ["VOC","VisDrone", "coco"],
  "yolov8x": ["VOC","VisDrone", "coco"],
  "mnist" : ["mnist"],
  "mnist_rnn" : ["mnist"],
  "siamese_net": ["mnist"],
  "super_resolution": ["bsd300"],
  "word_language": ["corpus"],
  "gat": ["cora"],
  "Pytorch_vae":["celeba_spoof", "celeba", "imagenet", "coco"],
  "Pytorch_vqvae":["celeba_spoof", "celeba", "imagenet", "coco"],
  "cql": ["mujoco_env"],
  "edac": ["mujoco_env"],
  "iql": ["mujoco_env"],
  "mcq": ["mujoco_env"],
  "td3bc": ["mujoco_env"],
  "dnn_beamformer":["L3DAS22"],
  "video_classification":["kinetics400"],
}
